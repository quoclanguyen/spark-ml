{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đồ án học máy sử dụng Apache Spark ML và SparkSQL\n",
    "* Đồ án này sử dụng pyspark phiên bản 3.4.0 và được chạy trên Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nhập dữ liệu và mô tả dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dữ liệu sử dụng một lược đồ tạo thủ công\n",
    "* Trong notebook này, dữ liệu sử dụng đó là dữ liệu chứa chi tiết của các chuyến bay\n",
    "* Ở những bước đầu tiên, nhóm thực hiện khám phá dữ liệu sau khi load nó vào DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkMLExample').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "|        19|        5|     DL|          14107|        13487|      -7|     -13|\n",
      "|        19|        5|     DL|          11433|        11298|      22|      41|\n",
      "|        19|        5|     DL|          11298|        11433|      40|      20|\n",
      "|        19|        5|     DL|          11433|        12892|      -2|      -7|\n",
      "|        19|        5|     DL|          10397|        12451|      71|      75|\n",
      "|        19|        5|     DL|          12451|        10397|      75|      57|\n",
      "|        19|        5|     DL|          12953|        10397|      -1|      10|\n",
      "|        19|        5|     DL|          11433|        12953|      -3|     -10|\n",
      "|        19|        5|     DL|          10397|        14771|      31|      38|\n",
      "|        19|        5|     DL|          13204|        10397|       8|      25|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the dataframe sql data types\n",
    "from pyspark.sql.types import *\n",
    "#\n",
    "# flightSchema describes the structure of the data in the flights.csv file\n",
    "#\n",
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "  StructField(\"DestAirportID\", IntegerType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "])\n",
    "#\n",
    "# Use the dataframe reader to read the file and \n",
    "#\n",
    "flights = spark.read.csv('data/raw-flight-data.csv', schema=flightSchema, header=True)\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dữ liệu sử dụng tính năng tự động tạo lược đồ\n",
    "* Nếu không định nghĩa sẵn lược đồ, có thể cho Spark đọc file và tạo schema tự động\n",
    "* Để minh hoạ, nhóm chọn tập dữ liệu `airports.csv` vì tính đơn giản của nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "|     10304|      Aniak|   AK|       Aniak Airport|\n",
      "|     10754|     Barrow|   AK|Wiley Post/Will R...|\n",
      "|     10551|     Bethel|   AK|      Bethel Airport|\n",
      "|     10926|    Cordova|   AK|Merle K Mudhole S...|\n",
      "|     14709|  Deadhorse|   AK|   Deadhorse Airport|\n",
      "|     11336| Dillingham|   AK|  Dillingham Airport|\n",
      "|     11630|  Fairbanks|   AK|Fairbanks Interna...|\n",
      "|     11997|   Gustavus|   AK|    Gustavus Airport|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports = spark.read.csv('data/airports.csv', header=True, inferSchema=True)\n",
    "airports.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lược đồ được tạo tự động từ Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the inferred schema for the airports dataframe\n",
    "airports.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng các method có sẵn trong DataFrame\n",
    "Spark DataFrames cung cấp nhiều hàm có sẵn dùng để trích xuất và xử lý dữ liệu.  \n",
    "Dưới đây là ví dụ dùng để hiển thị 5 thành phố đầu tiên trong tập dữ liệu về sân bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|       city|                name|\n",
      "+-----------+--------------------+\n",
      "|Adak Island|                Adak|\n",
      "|  Anchorage|Ted Stevens Ancho...|\n",
      "|      Aniak|       Aniak Airport|\n",
      "|     Barrow|Wiley Post/Will R...|\n",
      "|     Bethel|      Bethel Airport|\n",
      "+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities = airports.select(\"city\", \"name\")\n",
    "cities.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minh hoạ một số toán tử\n",
    "Toán tử trong SparkSQL được sử dụng tương tự như trong SQL.  \n",
    "Ở đây, sử dụng toán tử JOIN để kết hợp bảng flights và airports, sau đó sử dụng GROUP BY và COUNT để đếm số chuyến bay từ mỗi sân bay.  \n",
    "Sau đó, dùng ORDERBY và LIMIT để hiện ra top 5 sân bay dựa trên tổng số chuyến bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|             city| Count|\n",
      "+-----------------+------+\n",
      "|          Chicago|177845|\n",
      "|          Atlanta|149970|\n",
      "|      Los Angeles|118684|\n",
      "|         New York|118540|\n",
      "|Dallas/Fort Worth|105024|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "flightsByOrigin = flights\\\n",
    ".join(airports, flights.OriginAirportID == airports.airport_id)\\\n",
    ".groupBy(\"city\")\\\n",
    ".agg(F.count(F.lit(1)).alias(\"Count\"))\\\n",
    ".orderBy(\"Count\", ascending=False)\n",
    "\n",
    "flightsByOrigin.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô tả thống kê của dữ liệu\n",
    "Trong đề tài này, dữ liệu dùng để huấn luyện được lấy từ tập flights. Do đó, để biết thấu hiểu dữ liệu một cách kỹ càng, thực hiện mô tả các giá trị thống kê trong dữ liệu bằng hàm describe:  \n",
    "Hàm này sẽ hiển thị các giá trị bao gồm count, mean, stddev, min, max tương ứng với số lượng, trung bình, độ lệch chuẩn, min, max của mỗi cột dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-------+------------------+------------------+-----------------+-----------------+\n",
      "|summary|       DayofMonth|         DayOfWeek|Carrier|   OriginAirportID|     DestAirportID|         DepDelay|         ArrDelay|\n",
      "+-------+-----------------+------------------+-------+------------------+------------------+-----------------+-----------------+\n",
      "|  count|          2719418|           2719418|2719418|           2719418|           2719418|          2691974|          2690385|\n",
      "|   mean|15.79747468024408|3.8983907586108497|   null| 12742.26441172339|12742.455345592329|10.53686662649788| 6.63768791455498|\n",
      "| stddev|8.799860168985404|1.9859881390373355|   null|1501.9729397025644|1501.9692528927876|36.09952806643144|38.64881489390081|\n",
      "|    min|                1|                 1|     9E|             10140|             10140|              -63|              -94|\n",
      "|    max|               31|                 7|     YV|             15376|             15376|             1863|             1845|\n",
      "+-------+-----------------+------------------+-------+------------------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Làm sạch dữ liệu và khám phá dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loại bỏ các dòng lặp lại\n",
    "Ở đây sử dụng `dropDuplicates` để loại bỏ dòng lặp lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows =  22435\n"
     ]
    }
   ],
   "source": [
    "total_flights = flights.count()\n",
    "unique_flights = flights.dropDuplicates().count()\n",
    "\n",
    "print(\"Number of duplicate rows = \",total_flights - unique_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm các dữ liệu `null` và loại bỏ, lấp đầy chúng\n",
    "Ở đây sử dụng `dropna` để loại bỏ các chuyến bay không có dữ liệu gì cả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (excluding dups) =  46233\n"
     ]
    }
   ],
   "source": [
    "unique_flights_withoutNA =  flights.dropDuplicates()\\\n",
    ".dropna(how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"]).count()\n",
    "\n",
    "print(\"Missing values (excluding dups) = \", total_flights - unique_flights_withoutNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Làm sạch dữ liệu\n",
    "Tiếp theo, dùng fillna để lấp đầy các dòng null ở cột ArrDelay và DepDelay thành giá trị 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in cleaned data set =  2696983 Number of partitions =  32\n"
     ]
    }
   ],
   "source": [
    "data = flights.dropDuplicates().fillna(value=0, subset=[\"ArrDelay\", \"DepDelay\"]).repartition(32)\n",
    "\n",
    "# Let's cache this for efficient future use\n",
    "data.cache()\n",
    "\n",
    "print(\"Number of rows in cleaned data set = \", data.count(), \"Number of partitions = \", data.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra lại giá trị thống kê\n",
    "\n",
    "Sau khi làm sạch dữ liệu, kiểm tra lại dòng count ở bảng thống kê. Nếu thấy tất cả bằng nhau, nghĩa là không còn các giá trị null không cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------+------------------+-----------------+------------------+------------------+\n",
      "|summary|        DayofMonth|         DayOfWeek|Carrier|   OriginAirportID|    DestAirportID|          DepDelay|          ArrDelay|\n",
      "+-------+------------------+------------------+-------+------------------+-----------------+------------------+------------------+\n",
      "|  count|           2696983|           2696983|2696983|           2696983|          2696983|           2696983|           2696983|\n",
      "|   mean|15.798996508320593| 3.900369412784582|   null|12742.459424846207|12742.85937657004|10.531134234068217|6.6679285705545785|\n",
      "| stddev| 8.801267199135454|1.9864582421701988|   null|1502.0359941370607|1501.993958981797| 36.06172819056576|38.583861473580725|\n",
      "|    min|                 1|                 1|     9E|             10140|            10140|               -63|               -94|\n",
      "|    max|                31|                 7|     YV|             15376|            15376|              1863|              1845|\n",
      "+-------+------------------+------------------+-------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng các method có sẵn để khám phá dữ liệu\n",
    "\n",
    "Kiểm tra mối quan hệ giữa DepDelay và ArrDelay thông qua hàm `corr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392630367706979"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr(\"DepDelay\", \"ArrDelay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị tương quan cao, cho thấy 2 biến này cùng tăng hoặc cùng giảm với nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng SparkSQL\n",
    "Sử dụng SparkSQL để hiển thị thời gian delay trung bình theo ngày trong tuần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|DayOfWeek|Avg Delay(min)|\n",
      "+---------+--------------+\n",
      "|        1|          7.08|\n",
      "|        2|          4.39|\n",
      "|        3|          7.23|\n",
      "|        4|         10.78|\n",
      "|        5|          8.71|\n",
      "|        6|          2.14|\n",
      "|        7|          5.25|\n",
      "+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.createOrReplaceTempView(\"flightData\")\n",
    "spark.sql(\"\"\" \n",
    "SELECT DayOfWeek, CAST(AVG(ArrDelay) as DECIMAL(6,2)) AS `Avg Delay(min)` \n",
    "FROM flightData \n",
    "GROUP BY DayOfWeek \n",
    "ORDER BY DayOfWeek \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây, 2 ngày 4 và 5 cho ra kết quả cao nhất, tương ứng với thứ 5 và thứ 6 trong tuần. Điều này cho thấy vào những ngày cao điểm trong tuần, thời gian trễ chuyến bay cao hơn và tăng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chuẩn bị dữ liệu, xây dựng pipeline và huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Chuẩn bị dữ liệu \n",
    "Để chuẩn dữ liệu, sử dụng dữ liệu đã làm sạch ở phần trước đó.  \n",
    "Dữ liệu dùng để train sẽ được giữ nguyên 6 cột đầu, cột cuối sẽ ánh xạ thành label, nếu ArrDelay > 15 thì label = 1, ngược lại label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import sql functions and ML libraries\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- OriginAirportID: integer (nullable = true)\n",
      " |-- DestAirportID: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select(\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", \\\n",
    "                   ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chia tập train và tập test\n",
    "Ở đây chia tập train và test theo tỉ lệ 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows count: 1887560  Testing rows count: 809423\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.7, 0.3], seed = 42)\n",
    "\n",
    "train = splits[0]\n",
    "# rename the target variable in the test set to trueLabel\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "\n",
    "print (\"Training rows count:\", train_rows, \" Testing rows count:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------\n",
      " DayofMonth      | 1     \n",
      " DayOfWeek       | 1     \n",
      " Carrier         | 9E    \n",
      " OriginAirportID | 10423 \n",
      " DestAirportID   | 11433 \n",
      " DepDelay        | -5    \n",
      " label           | 0     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuẩn bị các stage để xử lý dữ liệu\n",
    "\n",
    "Trong đoạn tiếp theo, SparkML được sử dụng để tạo ra 7 stage. 7 Stages này sẽ được đưa vào 1 pipeline để tạo thành 1 quy trình xử lý\n",
    "1. **StringIndexer** chuyển các biến định danh thành biến thứ tự\n",
    "2. **VectorAssembler** gom các biến thứ tự thành 1 vector\n",
    "3. **VectorIndexer** tạo chỉ mục cho vector chứa biến thứ tự ở stage 2\n",
    "4. **VectorAssembler** tạo vector chứa giá trị biến liên tục\n",
    "5. **MinMaxScaler** chuẩn hoá vector ở stage 4\n",
    "6. **VectorAssembler** tạo vector đặc trưng chứa vector biến thứ tự ở stage 3 và vector chuẩn hoá ở stage 5\n",
    "7. **LogisticRegression** mô hình phân loại sử dụng logistic regression để phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#Stage 1. convert string values to indexes for categorical features\n",
    "strIdx = StringIndexer(inputCol = \"Carrier\", outputCol = \"CarrierIdx\")\n",
    "\n",
    "#Stage 2. combine categorical features into a single vector\n",
    "catVect = VectorAssembler(inputCols = [\"CarrierIdx\", \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\"], outputCol=\"catFeatures\")\n",
    "\n",
    "#Stage 3. create indexes for a vector of categorical features\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "\n",
    "#Stage 4. create a vector of continuous numeric features\n",
    "numVect = VectorAssembler(inputCols = [\"DepDelay\"], outputCol=\"numFeatures\")\n",
    "\n",
    "#Stage 5. normalize continuous numeric features\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "\n",
    "#Stage 6. creates a vector of categorical and continuous features\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "\n",
    "#Stage 7. LogisticRegression classifier that trains a classification model\n",
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "\n",
    "# Now define the pipeline\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện mô hình\n",
    "Pipeline được khớp dữ liệu train vào để huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete in: 9.96788129999959 secs\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "piplineModel = pipeline.fit(train)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print(\"Model training complete in:\", elapsed, \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiển thị giá trị trung gian giữa các stage trong khi huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------\n",
      " DayofMonth      | 1                                                  \n",
      " DayOfWeek       | 7                                                  \n",
      " Carrier         | 9E                                                 \n",
      " OriginAirportID | 10423                                              \n",
      " DestAirportID   | 11433                                              \n",
      " DepDelay        | -2                                                 \n",
      " label           | 0                                                  \n",
      " CarrierIdx      | 10.0                                               \n",
      " catFeatures     | [10.0,1.0,7.0,10423.0,11433.0]                     \n",
      " idxCatFeatures  | [10.0,1.0,6.0,10423.0,11433.0]                     \n",
      " numFeatures     | [-2.0]                                             \n",
      " normFeatures    | [0.02610966057441253]                              \n",
      " features        | [10.0,1.0,6.0,10423.0,11433.0,0.02610966057441253] \n",
      " rawPrediction   | [1.6049265199350258,-1.6049265199350258]           \n",
      " probability     | [0.8327058084357397,0.1672941915642603]            \n",
      " prediction      | 0.0                                                \n",
      "-RECORD 1-------------------------------------------------------------\n",
      " DayofMonth      | 1                                                  \n",
      " DayOfWeek       | 7                                                  \n",
      " Carrier         | 9E                                                 \n",
      " OriginAirportID | 11433                                              \n",
      " DestAirportID   | 13244                                              \n",
      " DepDelay        | -3                                                 \n",
      " label           | 0                                                  \n",
      " CarrierIdx      | 10.0                                               \n",
      " catFeatures     | [10.0,1.0,7.0,11433.0,13244.0]                     \n",
      " idxCatFeatures  | [10.0,1.0,6.0,11433.0,13244.0]                     \n",
      " numFeatures     | [-3.0]                                             \n",
      " normFeatures    | [0.02558746736292428]                              \n",
      " features        | [10.0,1.0,6.0,11433.0,13244.0,0.02558746736292428] \n",
      " rawPrediction   | [1.6285935736858057,-1.6285935736858057]           \n",
      " probability     | [0.8359768813689663,0.1640231186310337]            \n",
      " prediction      | 0.0                                                \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "piplineModel.transform(train).filter(\"DayOfWeek == 7\").show(2, vertical=True, truncate = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kiểm tra mô hình\n",
    "\n",
    "Sử dụng hàm transform có sẵn trong mô hình để đưa vào tập test, trả về kết quả các nhãn dự đoán.  \n",
    "Thực hiện so sánh với nhãn thật (`trueLabel`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+----------+---------+\n",
      "|features                                           |prediction|trueLabel|\n",
      "+---------------------------------------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,11057.0,12478.0,0.02558746736292428] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10423.0,0.02402088772845953] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14122.0,0.02506527415143603] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.021409921671018278]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11278.0,0.02506527415143603] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,12264.0,0.027154046997389034]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14100.0,0.05430809399477807] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,13487.0,11193.0,0.02349869451697128] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13487.0,14730.0,0.03185378590078329] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,14122.0,11433.0,0.05378590078328981] |0.0       |1        |\n",
      "+---------------------------------------------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = piplineModel.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "predicted.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Đánh giá kết quả và hiệu chỉnh mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá kết quả: Tính các giá trị trong ma trận lỗi\n",
    "Để đánh giá kết quả, tính các thang đo sau:  \n",
    "$TP$: True Positive, khi nhãn dự đoán là 1 và nhãn thật là 1  \n",
    "$FP$: False Positive, khi nhãn dự đoán là 1 và nhãn thật là 0  \n",
    "$TN$: True Negative, khi nhãn dự đoán là 0 và nhãn thật là 1  \n",
    "$FN$: False Negative, khi nhãn dự đoán là 0 và nhãn thật là 0  \n",
    "Precision = $\\frac{TP}{TP+FP}$  \n",
    "Recall = $\\frac{TP}{TP+FN}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(tp, fp, tn, fn):\n",
    "    print(f\"TP = {tp}\")\n",
    "    print(f\"FP = {fp}\")\n",
    "    print(f\"TN = {tn}\")\n",
    "    print(f\"FN = {fn}\")\n",
    "    print(f\"Precision = {tp / (tp + fp)}\")\n",
    "    print(f\"Recall = {tp / (tp + fn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 19277.0\n",
      "FP = 81.0\n",
      "TN = 647526.0\n",
      "FN = 142539.0\n",
      "Precision = 0.9958156834383717\n",
      "Recall = 0.11912913432540663\n"
     ]
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND trueLabel == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND trueLabel == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND trueLabel == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND trueLabel == 1\").count())\n",
    "show_metrics(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tính giá trị AUC\n",
    "Sử dụng BinaryClassificationEvaluator để tính AUC. Giá trị AUC càng gần 1 thì mô hình càng dự đoán không ngẫu nhiên, có cơ sở"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve =  0.9230114851471186\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(prediction)\n",
    "print (\"Area under the ROC curve = \", aur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiệu chỉnh mô hình\n",
    "\n",
    "Giá trị ngưỡng mặc định của LogisticRegression là 0.5, tức là khi tính toán dựa vào các trọng số, nếu ra kết quả > 0.5 thì nhãn dự đoán là 1, ngược lại là 0. Ta thấy ở trên Recall khá thấp, vậy nên để tăng Recall thì phải giảm FN xuống bằng cách hạ threshold xuống 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "|rawPrediction                           |probability                             |prediction|trueLabel|\n",
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "|[1.6028410930250616,-1.6028410930250616]|[0.83241509258929,0.16758490741070997]  |0.0       |0        |\n",
      "|[1.6472109887757473,-1.6472109887757473]|[0.8385137512235306,0.16148624877646944]|0.0       |0        |\n",
      "|[1.620881286552173,-1.620881286552173]  |[0.8349166341374121,0.16508336586258787]|0.0       |0        |\n",
      "|[1.7256164253104487,-1.7256164253104487]|[0.8488508537665199,0.15114914623348008]|0.0       |0        |\n",
      "|[1.6287422788121078,-1.6287422788121078]|[0.8359972707280444,0.16400272927195558]|0.0       |0        |\n",
      "|[1.5731771293119245,-1.5731771293119245]|[0.8282360615979741,0.17176393840202586]|0.0       |0        |\n",
      "|[0.845853440305421,-0.845853440305421]  |[0.6996965841835985,0.3003034158164015] |0.0       |1        |\n",
      "|[1.679547349837816,-1.679547349837816]  |[0.8428445834684515,0.15715541653154852]|0.0       |0        |\n",
      "|[1.4571023104402352,-1.4571023104402352]|[0.8110890805904518,0.18891091940954818]|0.0       |0        |\n",
      "|[0.8730423658563913,-0.8730423658563913]|[0.7053783564708992,0.2946216435291008] |0.0       |1        |\n",
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change the threshold to 0.3 and create a new LogisticRegression model\n",
    "lr2 = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3, threshold=0.35)\n",
    "\n",
    "#Set up new pipeline\n",
    "pipeline2 = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr2])\n",
    "model2 = pipeline2.fit(train)\n",
    "\n",
    "#Make new predictions\n",
    "newPrediction = model2.transform(test)\n",
    "newPrediction.select(\"rawPrediction\", \"probability\", \"prediction\", \"trueLabel\")\\\n",
    ".show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 42021.0\n",
      "FP = 134.0\n",
      "TN = 647473.0\n",
      "FN = 119795.0\n",
      "Precision = 0.996821254892658\n",
      "Recall = 0.2596838384337766\n"
     ]
    }
   ],
   "source": [
    "# Recalculate confusion matrix, using the new predictions\n",
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "\n",
    "show_metrics(tp2, fp2, tn2, fn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chú ý rằng FN đã giảm và FP đã tăng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiệu chỉnh mô hình với CrossValidator\n",
    "\n",
    "Sử dụng kỹ thuật CrossValidation và ParamGridBuilder để tạo ra các khoảng của các tham số của bộ phân loại LR. Khi đó, Cross Validator sẽ tạo ra các pipeline và thay đổi từng tham số trong khoảng được định nghĩa trong ParamGridBuilder, nhằm tìm ra tham số tốt nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    ".addGrid(lr.regParam, [0.3])\\\n",
    ".addGrid(lr.maxIter, [10])\\\n",
    ".addGrid(lr.threshold, [0.25, 0.3, 0.35])\\\n",
    ".build()\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(),\\\n",
    "                    estimatorParamMaps=paramGrid, numFolds=5)\n",
    "\n",
    "modelCV = cv.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kiểm tra mô hình trên tập test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+----------+---------+\n",
      "|features                                           |prediction|trueLabel|\n",
      "+---------------------------------------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,11057.0,12478.0,0.02558746736292428] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10423.0,0.02402088772845953] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14122.0,0.02506527415143603] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.021409921671018278]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11278.0,0.02506527415143603] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,12264.0,0.027154046997389034]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14100.0,0.05430809399477807] |1.0       |1        |\n",
      "|[10.0,1.0,0.0,13487.0,11193.0,0.02349869451697128] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13487.0,14730.0,0.03185378590078329] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,14122.0,11433.0,0.05378590078328981] |1.0       |1        |\n",
      "+---------------------------------------------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionCV = modelCV.transform(test)\n",
    "predictedCV = predictionCV.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "predictedCV.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 86496.0\n",
      "FP = 1574.0\n",
      "TN = 646033.0\n",
      "FN = 75320.0\n",
      "Precision = 0.9821278528443284\n",
      "Recall = 0.5345330498838187\n"
     ]
    }
   ],
   "source": [
    "# Recalculate confusion matrix, using the new predictions\n",
    "tp3 = float(predictionCV.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp3 = float(predictionCV.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn3 = float(predictionCV.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn3 = float(predictionCV.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "\n",
    "show_metrics(tp3, fp3, tn3, fn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall đã tăng lên 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bestPipeline = modelCV.bestModel\n",
    "bestLRModel = bestPipeline.stages[6]\n",
    "bestParams = bestLRModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  LogisticRegression_cd1c8d81c1ef__aggregationDepth  ---> Value =  2\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__elasticNetParam  ---> Value =  0.0\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__family  ---> Value =  auto\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__featuresCol  ---> Value =  features\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__fitIntercept  ---> Value =  True\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__labelCol  ---> Value =  label\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__maxBlockSizeInMB  ---> Value =  0.0\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__maxIter  ---> Value =  10\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__predictionCol  ---> Value =  prediction\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__probabilityCol  ---> Value =  probability\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__rawPredictionCol  ---> Value =  rawPrediction\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__regParam  ---> Value =  0.3\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__standardization  ---> Value =  True\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__threshold  ---> Value =  0.25\n",
      "Key:  LogisticRegression_cd1c8d81c1ef__tol  ---> Value =  1e-06\n"
     ]
    }
   ],
   "source": [
    "#type(bestParams)\n",
    "for k,v in bestParams.items():\n",
    "    print(\"Key: \", k, \" ---> Value = \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các tham số tốt nhất cho mô hình LogisticRegression sau khi áp dụng CrossValidator để tìm tham số  \n",
    "Threshold tốt nhất là 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve =  0.9230119021256126\n"
     ]
    }
   ],
   "source": [
    "eval2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur2 = eval2.evaluate(predictionCV)\n",
    "print (\"Area under the ROC curve = \", aur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Không có sự thay đổi lớn của AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
